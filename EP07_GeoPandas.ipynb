{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Geopandas to Read and Write Vector Data\n",
    "\n",
    "<img width=\"20%\" src=\"https://geopandas.readthedocs.io/en/latest/_static/geopandas_logo_web.svg\"></img>\n",
    "\n",
    "\n",
    "GeoPandas is a popular Python library designed to simplify working with geospatial data in Python by extending the capabilities of the pandas library. It provides data structures and functions needed to manipulate and analyze geospatial data, such as points, lines, and polygons, and to perform various spatial operations, like spatial joins, overlays, and projections.\n",
    "\n",
    "GeoPandas builds upon several core Python libraries, including pandas, Shapely, Fiona, and pyproj. These dependencies provide the underlying functionality for handling geospatial data structures, file I/O, and coordinate transformations.\n",
    "\n",
    "http://geopandas.readthedocs.io\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cam import geopandas. Most developers import it as \"gpd\" to type less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Reading Natural Earth Dataset\n",
    "\n",
    "In the previous lecture we downloaded the natural earth vector dataset and looked at the airports and countries datasets. \n",
    "\n",
    "Let's do that again but this time using GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"geodata/packages/natural_earth_vector.gpkg\"\n",
    "\n",
    "airports = gpd.read_file(filename, layer=\"ne_10m_airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the variable \"airports\" is a \"geopandas data frame\". We can just display it in jupyter lab:\n",
    "\n",
    "The last column is \"geometry\" and contains the geometry. Compared to fiona this is really easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 41 columns and 893 rows. The geodataframe has an attribute \"shape\", where we can also get this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new dataframe with less rows by just telling which rows we want. We should always keep the **geometry** row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2 = airports[['scalerank', 'type', 'name','iata_code', 'geometry']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also call .head(n) to display the first n entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "Sorting is very easy. You must specify which column is sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2.sort_values(by=\"name\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries\n",
    "\n",
    "We can do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2.query(\"scalerank == 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports2.query(\"iata_code == 'ZRH'  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Creating a Geopandas dataframe manually and exporting it\n",
    "\n",
    "Let's assume we have some data and want to create a geopandas dataframe from scratch.\n",
    "\n",
    "We have a list of mountain peaks in Switzerland in the format [latitude, longitude, name, elevation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[45.922513343092916, 7.835574679184418,'Liskamm',4527],\n",
    "[45.941997570720375, 7.869820276613906,'Nordend',4609],\n",
    "[46.10902325837147, 7.863895545667632,'Nadelhorn',4327],\n",
    "[45.932186337151684, 7.8714190183674555,'Zumsteinspitze',4563],\n",
    "[46.08336532442726, 7.857296913890337,'Täschhorn',4491],\n",
    "[45.91669904679932, 7.863563975062021,'Ludwigshöhe',4341],\n",
    "[45.93756139078208, 7.299279971077615,'Grand Combin de Grafeneire',4314],\n",
    "[45.922513343092916, 7.835574679184418,'Lyskamm',4527],\n",
    "[45.93683662540408, 7.866814344981748,'Dufourspitze (Pointe Dufour)',4634],\n",
    "[46.10129664518156, 7.716156885858494,'Weisshorn',4506],\n",
    "[45.976340506120614, 7.658691510512221,'Monte Cervino',4478],\n",
    "[45.976340506120614, 7.658691510512221,'Matterhorn',4478],\n",
    "[45.93674004101607, 7.86855410887458,'Grenzgipfel',4618],\n",
    "[45.92712756883081, 7.876921984235257,'Signalkuppe (Punta Gnifetti)',4554],\n",
    "[46.093839189553464, 7.858928716434883,'Dom',4545],\n",
    "[46.107109586833495, 7.711724522200983,'Grand Gendarme',4331],\n",
    "[45.919638502715564, 7.8711910872756405,'Parrotspitze',4432],\n",
    "[46.093839189553464, 7.858928716434883,'Mischabel',4545],\n",
    "[46.03426257063022, 7.61204033560156,'Dent Blanche',4357]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is we have to convert this list to a columns based approach using dictionary, e.g.\n",
    "\n",
    "\n",
    "    data_as_dict = {\"Longitude\": [list of longitudes],\n",
    "                    \"Latitude\":  [list of latitudes],\n",
    "                    \"Name\": [list of names],\n",
    "                    \"Elevation\": [list of elevation values]}\n",
    "    \n",
    "    \n",
    "So lets create an empty dictionary and add data to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_dict = {\"Longitude\": [],\n",
    "                \"Latitude\": [],\n",
    "                \"Name\": [],\n",
    "                \"Elevation\": []}\n",
    "\n",
    "for row in data:\n",
    "    data_as_dict[\"Latitude\"].append(row[0])\n",
    "    data_as_dict[\"Longitude\"].append(row[1])\n",
    "    data_as_dict[\"Name\"].append(row[2])\n",
    "    data_as_dict[\"Elevation\"].append(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do have a dictionary with data in \"columns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_as_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a pandas (not geopandas) dataframe out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't that great? The only problem is we don't have a GeoPandas dataframe. To do that we have to know about the Python Module Shapely (which will be introduced in Lecture 11). Shapely comes with Point, LineString, Polygon etc. classes where we can convert the geometry to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_dict_geo = {\"Name\": [],\n",
    "                \"Elevation\": [],\n",
    "                \"geometry\": []}\n",
    "\n",
    "for row in data:\n",
    "    p = Point(row[1],row[0]) # first longitude, then latitude\n",
    "    data_as_dict_geo[\"geometry\"].append(p)\n",
    "    data_as_dict_geo[\"Name\"].append(row[2])\n",
    "    data_as_dict_geo[\"Elevation\"].append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_as_dict_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a GeoDataFrame out of it. The option \"crs\" specifies the coordinate reference system which is WGS84. (We will learn about that in the next lecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(data_as_dict_geo, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can export the GeoDataframe. We can use any format supported for writing from fiona.\n",
    "\n",
    "    import fiona\n",
    "    \n",
    "    fiona.supported_drivers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"geodata/mountainpeaks.shp\", driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we could open it using QGIS..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: USGS Earthquake Data\n",
    "\n",
    "The United States Geological Survey (USGS) provides earthquake data in GeoJSON format through their Earthquake Hazards Program. This data contains information about recent and historical earthquakes, including their locations, magnitudes, depths, and other relevant attributes.\n",
    "\n",
    "The USGS earthquake data is available through their API, which allows you to query and filter the data based on various criteria, such as time range, magnitude range, and geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "#url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/significant_month.geojson\"\n",
    "#url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_month.geojson\"\n",
    "\n",
    "data = requests.get(url)\n",
    "file = open(\"geodata/earthquakes.geojson\",\"wb\")\n",
    "file.write(data.content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes = gpd.read_file(\"geodata/earthquakes.geojson\")\n",
    "quakes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes = quakes[[\"time\",\"mag\", \"place\",\"geometry\"]].copy()\n",
    "quakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.mag.hist(bins=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "datetime.fromtimestamp(1602758052977/1000, timezone.utc) # time in **seconds** since 1.1.1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "data = []\n",
    "for row in range(0,len(quakes)):\n",
    "    time = quakes.iloc[row].time\n",
    "    t = str(datetime.fromtimestamp(time/1000.0, timezone.utc))\n",
    "    data.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes[\"time_utc\"] = data\n",
    "quakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes = quakes.drop([\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes2 = quakes[[\"time_utc\", \"place\", \"mag\", \"geometry\"]].copy()\n",
    "quakes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.sort_values([\"mag\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to draw earthquakes on a map. So let's look at that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfCountries = gpd.read_file(\"geodata/packages/natural_earth_vector.gpkg\", \n",
    "                              layer=\"ne_110m_admin_0_countries\", \n",
    "                              encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfCountries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdfCountries.plot(figsize=(20,10), facecolor=\"#BBFFBB\", edgecolor=\"#000000\")\n",
    "quakes.plot(ax=ax, color=\"#005500\", markersize=40);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
